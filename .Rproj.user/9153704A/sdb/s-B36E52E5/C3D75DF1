{
    "contents" : "---\ntitle: \"Data Science Specialization - 8.PML - Final Project\"\nauthor: \"jmvilaverde\"\ndate: \"Monday, July 13, 2015\"\noutput: html_document\n---\n\n## Background\n\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. \n\nMore information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). \n\n***\n\n## Model creation\n\n### Extract, transform and load data\n\n* The training data for this project are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\n\n* The test data are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\n\n_Code 01. Extract files and data._\n\n```{r extract, echo=TRUE, cache=TRUE}\n########################\n#Extract files and data#\n########################\n\ninitValues <- function(){\n        \n        #Set URL path\n        URLTraining <<- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n        URLTesting <<- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n\n        #Set csv name\n        fileTraining <<- \"training.csv\"\n        fileTesting <<- \"testing.csv\"\n}\n\nextractData <- function(){\n        \n        #Init values and setup access to https\n        initValues()\n        setInternet2(use = TRUE)\n\n        #Adquire training file\n        if (!file.exists(fileTraining)) download.file(URLTraining, fileTraining)\n        trainingData <<- read.csv(fileTraining)\n        \n        #Adquire testing file\n        if (!file.exists(fileTesting)) download.file(URLTesting, fileTesting)\n        testingData <<- read.csv(fileTesting)\n\n}\n\nextractData()\n```\n\n***\n\n### Initial Data analysis\n\nBased on information and data extracted from: (http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises)\n\n> ###### Please, cite this paper to refer the WLE dataset: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.\n> ###### Read more: (http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises#ixzz3fnKRBc4a)\n\nThe objective of this data is to define quality of execution.\n\nSix young health participants (`r unique(trainingData$user_name)`)  were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashion that was stored into **classe** variable with these 5 types:\n\nFashion | Classification                         | Type\n------- | -------------------------------------- | -----------\nA       | exactly according to the specification | Correct\nB       | throwing the elbows to the front       | Mistake\nC       | lifting the dumbbell only halfway      | Mistake\nD       | lowering the dumbbell only halfway     | Mistake\nE       | throwing the hips to the front         | Mistake\n\nThere is a total of **`r ncol(trainingData)-1`** variables as predictors. \n\nData collects information from 4 sensors (belt, arm, dumbbell, forearm), each sensor has 3 detectors (acceleration, gyroscope and magnetometer) and each detector has 3 axis **(x, y, z)**, that makes a total of 36 variables. Other sensors predictors are derivated from these predictors.\n\nFor our analysis model are selected as relevant sensors predictors these:\n\n> ##### `r colnames(trainingData[,grep(\"_x$|_y$|_z$\", colnames(trainingData))])`\n\nAlso, exists a **user_name** predictor, that indicates who is the user, including this predictor increases the prediction accuracy when the user has participated on training.\n\nOther relevant predictors are **new\\_window** (indicates start of repetition) and **num\\_window** (indentificates a repetition).\n\n***\n\n### Proposal\n\nAre proposed two model options based on these premises:\n\nIncluded into both models:\n\n* It's presumed that sensors are basic to prediction.\n* Because the prediction is about users that participates on training, include user_name as predictor have to improve accuracy.\n\nIncluded into final model:\n\n* When starts repetition new\\_window and which repetition is num\\_window can be relevant to prediction.\n\n***\n\n### Initial Model: sensors and user name: 37 predictors: X, y and z axis for sensors + user_name.\n\nPredictors:\n\n> ##### `r colnames(trainingData[,grep(\"_x$|_y$|_z$|user\", colnames(trainingData))])`\n\nFor combined model is used a Random Forest model that is a combination of LDA, Booting and Random Forest model's predictions.\n\nCross validation: \n\n* Dataset for training, testing and validanting contains 37 preditors and classe.\n* Separate Training Data into three sets: 60% training set, 20% testing set and 20% validating set.\n* Validation set is used to confirm the results obtained with testing set.\n\n```{r modelSensorsUserDataSet, message=FALSE}\nrequire(caret)\nrequire(kernlab)\nrequire(pROC)\n\n#Based on training data create training sets and test sets\nset.seed(1525)\n\nDataset <- trainingData[,grep(\"_x$|_y$|_z$|user|classe\", colnames(trainingData))]\n\ninBuild <- createDataPartition(y=Dataset$classe, p=0.8, list=FALSE)\n\n#validation set\nvalidation <- Dataset[-inBuild,]\n\nbuildData <- Dataset[inBuild,]\n\ninTrain <- createDataPartition(y=buildData$classe, p=0.75, list=FALSE)\n\n#training set\ntrainingSet <- buildData[inTrain,]\n\n#testing set\ntestingSet <- buildData[-inTrain,]\n```\n\nSet             | %     | Sample dimension\n--------------- | ----- | -----------------------\nTraining        | 60%   | `r dim(trainingSet)[1]`\nTesting         | 20%   | `r dim(testingSet)[1]`\nValidating      | 20%   | `r dim(validation)[1]`\n\n\n#### LDA Model: Linear discriminant analysis\n\n```{r modelLDASensorsUser}\nrequire(MASS)\n\nload(\"models/modelLDA.rda\")\nif (!exists(\"modelLDA\")) {\n\n        modelLDA <- train(classe ~ ., data = trainingSet, method=\"lda\")\n        save(modelLDA, file=\"models/modelLDA.rda\")\n}\n\npredictedLDA <- predict(modelLDA, testingSet)\ncmLDAt <- confusionMatrix(predictedLDA, testingSet$classe)\n#Accuracy : 0.6628 Kappa : 0.5721\npredictedLDAv <- predict(modelLDA, validation)\ncmLDAv <- confusionMatrix(predictedLDAv, validation$classe)\n#Accuracy : 0.6538 Kappa : 0.5605\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmLDAt$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmLDAv$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n\n#### GBM model: Gradient Boosting Machine\n\n```{r modelGBMSensorsUser}\nrequire(gbm)\nload(\"models/modelGBM.rda\")\nif (!exists(\"modelGBM\")) {\n        modelGBM <- train(classe ~ ., data = trainingSet, method=\"gbm\")\n        save(modelGBM, file=\"models/modelGBM.rda\")\n}\n\npredictedGBM <- predict(modelGBM, testingSet)\ncmGBMt <- confusionMatrix(predictedGBM, testingSet$classe)\n#Consumes a lot of computing time +- 15 minutos\n#Accuracy : 0.9123 Kappa : 0.8889\npredictedGBMv <- predict(modelGBM, validation)\ncmGBMv <- confusionMatrix(predictedGBMv, validation$classe)\n#Accuracy : 0.9039 Kappa : 0.8782\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmGBMt$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmGBMt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n#### RF model: Random Forest.\n\n* Parameters: ntree = 100\n\n```{r modelRFSensorsUser}\nrequire(randomForest)\nload(\"models/modelRF.rda\")\nif (!exists(\"modelRF\")) {\n        modelRF <- train(classe ~ ., data = trainingSet, method=\"rf\", do.trace=10, ntree=100)\n        save(modelRF, file=\"models/modelRF.rda\")\n}\n\npredictedRF <- predict(modelRF, testingSet)\ncmRFt <- confusionMatrix(predictedRF, testingSet$classe)\n#Consumes a lot of computing time 6 minutes\n#Accuracy : 0.9801 Kappa : 0.9748 Mcnemar's Test P-Value : NA\npredictedRFv <- predict(modelRF, validation)\ncmRFv <- confusionMatrix(predictedRFv, validation$classe)\n# Accuracy : 0.9809 Kappa : 0.9758 Mcnemar's Test P-Value : NA\n``` \n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmRFt$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmRFt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n\n#### Combined model: Random forest from other model's predictions\n\n* Parameters: ntree = 100\n\n```{r modelCombined}\n#Model combined\npredCompDF <- data.frame(predictedLDA, predictedGBM, predictedRF, y=testingSet$classe)\n\nload(\"models/combMod.rda\")\nif (!exists(\"combMod\")) {\n        combMod <- train(y ~ ., data = predCompDF, method=\"rf\", do.trace=10, ntree=100)\n        save(\"combMod\", file=\"models/combMod.rda\")\n}\n\n#Time to predict:\ncombPred <- predict(combMod, testingSet)\ncmCombt <- confusionMatrix(combPred, testingSet$classe)\n#Accuracy : 0.9801 Kappa : 0.9748\ncombPredv <- predict(combMod, validation)\ncmCombv <- confusionMatrix(combPredv, validation$classe)\n#Accuracy : 0.9801 Kappa : 0.9748\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmCombt$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmCombt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n```{r predictionComb}\n#Prediction of testingData Set to upload as result\ntpredictedLDA <- predict(modelLDA, testingData)\ntpredictedGBM <- predict(modelGBM, testingData)\ntpredictedRF <- predict(modelRF, testingData)\n\nnewdataset <- data.frame(tpredictedLDA, tpredictedGBM, tpredictedRF)\ncolnames(newdataset) <- colnames(predCompDF[,1:3])\n\ntpredictedComb <- predict(combMod, newdata = newdataset)\n\nresult <- rbind(seq(1:20), as.character(tpredictedLDA), as.character(tpredictedGBM), as.character(tpredictedRF), as.character(tpredictedComb))\n\nresult\n```\n\nEstimated accuracy for testing set with this predictors:\n\nModel | Accuracy                        | Accuracy 95%\n----- | ------------------------------- | ------------------------- \nLDA   | `r cmLDAt$overall[\"Accuracy\"]`  | `r cmLDAt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")]`\nGBM   | `r cmGBMt$overall[\"Accuracy\"]`  | `r cmGBMt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")]`\nRF    | `r cmRFt$overall[\"Accuracy\"]`   | `r cmRFt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")]`\nComb  | `r cmCombt$overall[\"Accuracy\"]` | `r cmCombt$overall[c(\"AccuracyLower\", \"AccuracyUpper\")]`\n\nPrediction for testing set: `r tpredictedComb #B A B A A E D B A A B C B A E E A B B B`\n\n***\n\n### Final Model: sensors and user name: 39 predictors: X, y and z axis for sensors + user_name + window.\n\nPredictors:\n\n> ##### `r colnames(trainingData[,grep(\"_x$|_y$|_z$|user|window\", colnames(trainingData))])`\n\nFor combined model is used a Random Forest model that is a combination of LDA, Booting and Random Forest model's predictions.\n\nCross validation: \n\n* Dataset for training, testing and validanting contains 39 preditors and classe.\n* Separate Training Data into three sets: 60% training set, 20% testing set and 20% validating set.\n* Validation set is used to confirm the results obtained with testing set.\n\n```{r modelSensorsUserWindowDataSet}\n\n#Based on training data create training sets and test sets\nrequire(caret)\nrequire(kernlab)\nrequire(pROC) #varImp()\n\n#Create a model only using x y z axis and user_name, window, classe\nset.seed(1525)\n\nDataset2 <- trainingData[,grep(\"_x$|_y$|_z$|classe|user|window\", colnames(trainingData))]\n\ninBuild2 <- createDataPartition(y=Dataset2$classe, p=0.8, list=FALSE)\nvalidation2 <- Dataset2[-inBuild2,]\n\nbuildData2 <- Dataset2[inBuild2,]\n\ninTrain2 <- createDataPartition(y=buildData2$classe, p=0.75, list=FALSE)\ntrainingSet2 <- buildData2[inTrain2,]\ntestingSet2 <- buildData2[-inTrain2,]\n\n```\n\nSet             | %     | Dimensions\n--------------- | ----- | --------------\nTraining        | 60%   | `r dim(trainingSet2)`\nTesting         | 20%   | `r dim(testingSet2)`\nValidating      | 20%   | `r dim(validation2)`\n\n\n#### Use a LDA Model: Linear discriminant analysis\n\n```{r modelLDASensorsUserWindow}\n#Model LDA\nrequire(MASS)\n\nload(\"models/modelLDA2.rda\")\nif (!exists(\"modelLDA2\")) {\n        modelLDA2 <- train(classe ~ ., data = trainingSet2, method=\"lda\")\n        save(modelLDA2, file=\"models/modelLDA2.rda\")\n}\n\npredictedLDA2 <- predict(modelLDA2, testingSet2)\ncmLDA2t <- confusionMatrix(predictedLDA2, testingSet2$classe)\n#Accuracy : 0.6702 Kappa : 0.5815\npredictedLDA2v <- predict(modelLDA2, validation2)\ncmLDA2v <- confusionMatrix(predictedLDA2v, validation2$classe)\n#Accuracy : 0.6643 Kappa : 0.5735  \n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmLDA2t$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmLDA2t$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n#### GBM model: Gradient Boosting Machine\n\n```{r modelGBMSensorsUserWindow}\n#Third model GBM\nrequire(gbm)\n\nload(\"models/modelGBM2.rda\")\nif (!exists(\"modelGBM2\")) {\n        modelGBM2 <- train(classe ~ ., data = trainingSet2, method=\"gbm\")\n        save(modelGBM2, file=\"models/modelGBM2.rda\")\n}\n\npredictedGBM2 <- predict(modelGBM2, testingSet2)\ncmGBM2t <- confusionMatrix(predictedGBM2, testingSet2$classe)\n#Consumes a lot of computing time 13:51 - 14:12\n#Accuracy : 0.9862 Kappa : 0.9826 Mcnemar's Test P-Value : NA\npredictedGBM2v <- predict(modelGBM2, validation2)\ncmGBM2v <- confusionMatrix(predictedGBM2v, validation2$classe)\n# Accuracy : 0.9845 Kappa : 0.9803 Mcnemar's Test P-Value : NA\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmGBM2t$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmGBM2t$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n#### RF model: Random Forest.\n\n* Parameters: ntree = 100\n\n```{r modelRFSensorsUserWindow}\n#Model Random Forest\nrequire(randomForest)\nload(\"models/modelRF2.rda\")\nif(!exists(\"modelRF2\")) {\n        modelRF2 <- train(classe ~ ., data = trainingSet2, method=\"rf\", do.trace=10, ntree=100)\n        save(modelRF2, file=\"models/modelRF2.rda\")\n}\n\npredictedRF2 <- predict(modelRF2, testingSet2)\ncmRF2t <- confusionMatrix(predictedRF2, testingSet2$classe)\n#Consumes a lot of computing time 14:18 - 14:27\n#Accuracy : 0.9954 Kappa : 0.9942\npredictedRF2v <- predict(modelRF2, validation2)\ncmRF2v <- confusionMatrix(predictedRF2v, validation2$classe)\n#Accuracy : 0.9954 Kappa : 0.9942\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmRF2t$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmRF2t$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\n#### Combined model: Random forest from other model's predictions\n\n* Parameters: ntree = 100\n\n```{r modelCombSensorsUserWindow}\n#Model combined\npredCompDF2 <- data.frame(predictedLDA2, predictedGBM2, predictedRF2, classe=testingSet2$classe)\nload(\"models/combMod2.rda\")\nif(!exists(\"combMod2\")) {\n        combMod2 <- train(classe ~ ., data = predCompDF2, method=\"rf\", do.trace=10, ntree=100)\n        save(combMod2, file=\"models/combMod2.rda\")\n}\n\n#Time to predict:\ncombPred2 <- predict(combMod2, testingSet2)\ncmComb2t <- confusionMatrix(combPred2, testingSet2$classe)\n# Accuracy : 0.9959 Kappa : 0.9948\nvalidationDataComb <- data.frame(predictedLDA2v, predictedGBM2v, predictedRF2v, y=validation2$classe)\ncolnames(validationDataComb) <- colnames(predCompDF2)\ncombPred2v <- predict(combMod2, validationDataComb)\ncmComb2v <- confusionMatrix(combPred2v, validationDataComb$classe)\n#Accuracy : 0.9962 Kappa : 0.9952\n\n#Prediction of testingData Set to upload as result\ntpredictedLDA2 <- predict(modelLDA2, testingData)\ntpredictedGBM2 <- predict(modelGBM2, testingData)\ntpredictedRF2 <- predict(modelRF2, testingData)\n\nnewdataset2 <- data.frame(tpredictedLDA2, tpredictedGBM2, tpredictedRF2)\ncolnames(newdataset2) <- colnames(predCompDF2[,1:3])\n\ntpredictedComb2 <- predict(combMod2, newdata = newdataset2)\n\nresult2 <- cbind(seq(1:20), as.character(tpredictedLDA2), as.character(tpredictedGBM2), as.character(tpredictedRF2), as.character(tpredictedComb2))\n\nresult\nresult2\ntpredictedComb2\n\ncombMod2$finalModel\n```\n\nSet             | Testing Set\n--------------- | ----------------------------------\nAccuracy        | `r ((cmComb2t$overall[\"Accuracy\"])*100)`%\nAccuracy(95%)   | `r ((cmComb2t$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100)`%\n\nOut of sample error is (1-Accuracy) testing & validating set\n\n\nSet             | Testing Set\n--------------- | ----------------------------------\nOSE             | `r (1-cmComb2t$overall[\"Accuracy\"])*100`%\nOSE(95%)        | `r (1-cmComb2t$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100`%\n\nSet             | Validating Set\n--------------- | ----------------------------------\nOSE             | `r (1-cmComb2v$overall[\"Accuracy\"])*100`%\nOSE(95%)        | `r (1-cmComb2v$overall[c(\"AccuracyLower\", \"AccuracyUpper\")])*100`%\n\nValidating Set `r 1-confusionMatrix(combPred2v, validationDataComb$classe)$overall[\"Accuracy\"]`\n\nPrediction results for this model: `r tpredictedComb2`\n\n```{r filesGeneration, echo=FALSE, eval=FALSE}\n#Code to generate the prediction results files\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"prediction/problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\npml_write_files(tpredictedComb2)\n```\n",
    "created" : 1436988524237.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3963088974",
    "id" : "C3D75DF1",
    "lastKnownWriteTime" : 1437061071,
    "path" : "D:/Privado/repos/8.PracticalMachineLearning/DataScienceSpecialization-8.PML-FinalProject/FinalProject.Rmd",
    "project_path" : "FinalProject.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}